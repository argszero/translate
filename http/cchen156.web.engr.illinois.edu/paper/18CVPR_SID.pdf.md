http://cchen156.web.engr.illinois.edu/paper/18CVPR_SID.pdf

# 摘要

由于低光子数和低信噪比，在低光下成像具有挑战性。短时间曝光的图像会受到噪音的影响，而长时间曝光会导致模糊，而且通常不切实际。已经提出了各种去噪，去模糊和增强技术，但是他们的有效性在极端条件下是有限的，例如晚上的的视频速率成像。为了支持低光下基于学习的图像处理流水的开发，我们引入了原始短曝光低光图像的数据集以及相应的长曝光参考图像。使用所提供的数据集，我们开发了一个基于完全卷积网络端到端训练的低光图像处理流水线。网络直接根据原始传感器数据进行操作，并取代了传统图像处理流水线的大部分，这种流水线往往在这些数据上表现不佳。我们对新数据集报告好的结果，分析影响性能的因素，并强调未来工作的机会。

# 1. 引言

噪声出现在任何成像系统中，但是它使得成像在低光照下特别具有挑战性。高ISO可以用来增加亮度，但也会放大噪音。可以使用后处理，比如放缩或直方图拉伸，但是这并不能解决由于光子计数较低导致但低信噪比（SNR）。有一些物理手段可以提高弱光信噪比，比如打开光圈，延长曝光时间和使用闪光灯。但是每一种都有起特有的缺点。例如，增加曝光时间会由于相机抖动或物体移动而导致模糊。

在低光下快速成像的挑战性在计算摄影界是总所周知的，但仍未解决。研究人员已经提出了用于去暗淡，去模糊和增强低光图像技术[34,16,42]。这些计数通常假定图像在稍微昏暗但环境中捕捉，并具有中等程度的噪声。相比之下，我们对照明严格受限（如月光）和短时间曝光（理想情况下是视频速率）的极端低光成像感兴趣。在这种情况下，传统的相机处理流出崩溃，图像必须从原始传感器数据重建。

图1说明了我们的设置。环境非常暗：相机的照度低于0.1 lux。曝光时间设定为1/30秒。光圈为f/5.6。在通常认为已经很高的ISO 8000的情况下，尽管全画副索尼传感器具有高感光度，但相机仍然会产生基本上为黑色的图像。ISO 409,600远远超出大多数相机的范围，场景内容可变，但图像暗淡，嘈杂，色彩失真。正如我们将要表明但那样，即使最先进但去噪技术[32]也不能消除这种噪声，也不能解决色偏问题。另一种方法是使用一连串但图像[24,14],但在极端低光照条件下，连拍对齐算法可能会失败，并且burst流水线不是为视频捕获设计的（例如，由于在内部使用了“幸运成像”burst）

我们提出了一种新的图像处理流水线，通过数据驱动的放缩解决极端低光照摄影的挑战。具体来说，我们训练深度神经网络来学习低光原始数据的图像处理流水线，包括颜色转换，去马赛克，降噪和图像增强。管道是端对端训练的，以避免噪声放大和误差累积，这是该系统中传统相机处理流水线的特点。
大多数现有的处理低光图像的方法都是在合成数据或真实低光图像上进行评估而没有参考标准。就我们所知，没有用于处理具有不同真实世界数据和基本事实的快速低光图像的训练和测试技术的公共数据集。因此，我们收集了在低光照条件下快速摄影的原始图像的新数据集。每个低光图像都具有对应的长曝光高质量参考图像。我们在新的数据集上展示了令人鼓舞的成果：低成像图像放大了300倍，成功的降噪和正确的颜色转换。我们系统的分析了管道的关键要素，并讨论了未来研究的方向。

# 2. 相关工作

在文献已经广泛研究了低光图像的计算处理。我们简要回顾一下现有的方法。

**图像去噪** 。 图像去噪是低级视觉中的一个发展良好的话题。已经提出了许多方法，使用诸如总变差[36]，小波域处理[33]，稀疏编码[9,28],核范数最小化[12]核3D变换域滤波[BM3D][7]。这些方法通常基于特定的图像先验，如平滑度，稀疏性，低秩或自相似性。研究人员还探索了深度网络在去噪中的应用，包括堆叠式稀疏降噪自动编码器（SSDA）[39,1],可训练非线性反应扩展（TNRD）[6],多层感知机[3],深度自动编码器[26]和卷积网络[17,41]。当在某些噪声水平上进行训练时，这些数据驱动的方法可以与BM3D和稀疏编码等现有经典技术相抗衡。不幸的是，大多数现有的方法都是在合成数据上进行评估的，例如带有高斯或椒盐噪声的图像。最近对真实数据的仔细评估发现，BM3D优于更多最新的真是图像技术[32]。还研究了联合去噪和去马赛克，其中包括最近使用的深度网络的工作[15,10],但这些方法已经用合成Bayer模式和合成噪声进行了评估，而不是在极端低光条件下收集但真实图像。

除了单图像去噪外，多图像去噪也已经被考虑并且可以获得更好但结果，因为从现场收集更多但信息[31,23,19,24,14,29]。特别是，刘等人[24]和Hasinoff等人[14]建议去噪同一场景中但一连串图像。虽然经常有效，但这些管道可以精心制作，涉及参考图像选择（‘幸运成像’）和密集的图像对应估计。我们专注于a complementary line of investigation和研究互补性的单线图像处理能力。

**低光图像增强**。 已经有各种技术用来增强低光图像的对比度。 一个经典的选择是直方图均衡，它可以平衡整个图像的直方图。另一个广泛使用的技术是伽马矫正，他可以在压缩亮像素的同时增加暗区的亮度。更先进的方法执行更多的全局分析和处理，例如使用逆暗通道[8,29],小波变换[27],Retinex模型[30]和照明图估计[13]。但是，这些方法通常假定图像已经包含场景内容的良好表示。它们没有明确的模拟图像噪声，并且通常将现成的去噪操作作为后续处理。相比之下，我们考虑极端低光成像，噪音和颜色失真严重超出了现有增强管道的操作条件。

**噪音图像数据集**。 虽然有很多关于图像去噪的研究，但大多数现有但方法都是在合成数据上进行评估但，例如带有高斯或椒盐噪声但干净图像。RENOIR数据集[2]被提出用真实但噪声图像进行基准去噪。然而，正如文献[32]所报道但，RENOIR数据集中但图像对有空间偏差。在低光照条件下，图像爆发已被用于降低噪声[24],但相关数据集不包含可靠的参考标准。Google HDR+ 数据集[14]不针对极端低光成像：数据集中但大部分图像都是白天捕获的。最近的达姆施塔特噪音数据集（DND）[32]旨在解决降噪社区对真实数据的需求，但这些图像是白天拍摄但，并不适用于评估低光照图像处理。据我们所知，没有公开的数据集包含原始低光图像和相应的基本事实。因此，我们收集这样一个数据集来支持这个领域的系统可重复研究。

Sony α7S II   | Filter array |  Exposure time (s) | # images
--------------|--------------|--------------------|---------
x300          | Bayer        |   1/10,1/30        | 1190
x250          | Bayer        |     1/25           | 699
x100          | Bayer        |     1/10           | 808


Fujifilm X-T2 | Filter array |  Exposure time (s) | # images
--------------|--------------|--------------------|---------
x300          | X-Trans      |     1/30           | 630
x250          | X-Trans      |     1/25           | 650
x100          | X-Trans      |     1/10           | 1117

表1. 夜视（See-In-the-Dark）（SID）数据集包含5094个原始短时间曝光图像，每个图像都有一个长时间曝光图像。图像由两台相机收集（顶部和底部）。从左到右：输入图像和参考图像之间的曝光时间比率，滤镜阵列，输入图像的曝光时间以及每个条件下的图像数量。

# 3. 夜视数据集

我们收集了一个新的数据集，用于训练和基准化原始低光图像的单图像处理。夜视数据集包含5094张原始短曝光图像，每张图像都有相应的长曝光参考图像。请注意，多个短时间曝光图像可以对应于相同的长时间曝光参考图像。例如，我们收集短曝光图像序列以评估突发降噪方法。序列中的每个图像被设计为独特的低光图像，因为每个这样的图像都包含真实的人工成像，并且对训练和测试非常有用。SID中不同的长时间曝光参考图像的数量是424.

数据集包含室内和室外图像。通常在夜间，月光或街道照明下拍摄室外图像。室外场景中照相机的照度一般在0.2 lux到5 lux之间。室内图像更暗。他们被关在常规灯封闭房间内，并为此设置了微弱的间接照明。室内场景中照相机的照度一般在0.03 lux和0.3 lux之间。

输入图像的曝光时间设定在1/30和1/10秒之间。用100至300倍的曝光时间拍摄对应的参考（基础真实）图像，即10至30秒。由于参考图像的曝光时间必须很长，因此数据集中的所有场景都是静态的。数据集汇总在表1中。参考图像的一个小样本显示在图2中。每个条件中大约20%的图像被随机选择以形成测试集合，另外10%被选择用于验证集合。

图2. SID数据集中的示例图像 排在前两排的是户外图像，排在最下面的是室内图像。长时间曝光参考（参考标准）图像显示在前面。短曝光输入图像（基本上是黑色）显示在后面。照相机的照度一般在室外为0.2 lux到5 lux之间，室内为0.03 lux到0.3 lux之间

使用两台相机拍摄图像：Sony α7S II和Fujifilm X-T2。这些相机有不同的传感器：索尼相机又一个全帧拜耳传感器，富士相机有一个APS-C X-Trans传感器。这支持评估由不同滤波器阵列产生的图像上的低光图像处理流水线。索尼的分辨率为4240*2832，富士图像的分辨率为6000*4000。索尼套装是使用两种不同的镜头收集的。

相机安装在坚固的三角架上。我们使用无反光镜相机来避免镜面拍打造成的震动。在每个场景中，相机设置（如光圈，ISO，对焦和焦距）都会进行调整，以最大限度的提高参考图像（长时间曝光图像）的质量。拍摄长曝光参考图像后，使用远程智能手机应用程序将曝光图像序列的曝光时间缩短100至300倍。在长时间曝光和短时间曝光图像之间没有接触相机。我们收集了短曝光图像的序列，以支持与理想爆发成像管线的比较，这种管线从完美对准中受益。

长时间曝光的参考图像可能仍然包含一些噪音，但对于这些图像来说，感知质量足够高以充当基本事实。我们的目标应用是在低光照条件下产生感知良好的图像，而不是彻底消除所有噪点或最大化图像对比度。

# 4. 方法

## 4.1 管道

在从成像传感器获取原始数据后，传统的图像处理流水线将应用一系列模块，如白平衡，去马赛克，去噪，锐化，色彩空间转换，伽马校正等。这些模块通常针对特定相机进行调整。江等人[18]提出使用大量局部，线性和学习（L3）滤波器来近似现代消费级成像系统中的复杂非线性流水线。然后传统流水线和L3流水线都不能成功处理快速低光成像，因为它们无法处理极低的信噪比。Hasinoff等人[14]描述了用于智能手机相机的突发成像流水线。改方法通过对齐和混合多个图像可以产生良好的结果，但是例如由于需要密集但对应性估计而引入一定程度但复杂度，并且可能不容易扩展到视频捕获，例如由于使用幸运成像。

我们建议使用端到端学习来实现快速低光图像的直接单图像处理。具体来说，我们训练全卷积网络（FCN）[22,25]来执行整个图像处理流水线。最近的工作表明，纯FCN可以有效的表示许多图像处理算法[40,5]。我们收到这项工作的启发，并研究了这种方法在极端低光图像中的应用。我们不使用传统相机处理管线生成的正常sRGB图像进行操作，而是使用原始传感器数据。


图3. 不同图像处理流水线结构（a）从上到下：传统的图像处理流水线，L3流水线[18]和突发成像流水线[14].(b)我们的管道。

图3.（b）说明了所提供的流水线结构，对于拜耳阵列，我们将输入打包到四个通道中，并相应的将空间分辨率降低到每个维度的两倍。对于X-Trans阵列（未在图中显示），原始数据以6*6块排列，我们通过交换相邻元素将它打包成9个通道而不是36个通道。我们减去黑色电平并按照所需的放大比例（例如，x100或x300）放缩数据。打包和放大的数据被送入全卷积网络。输出是具有一半空间分辨率的12通道图像。这个半尺寸的输出又一个子像素层处理以恢复原始分辨率[37].

在初步探索之后，我们关注了构成我们管道核心的全卷积网络的两个一般结构：最近用于快速图像处理的多尺度上下文聚合网络（CAN）[5]和U网[25].其他研究已经探索了剩余连接[20,34,41],但是我们没有在我们的环境中找到这些有益的，可能是因为我们的输入和输出表现在不同的彩色空间。影响我们选择体系结构的另外一个考虑因素是内存消耗：我们选择了可以在GPU内存中处理全分辨率图像（例如，分辨率为4240*2832或6000*4000）的体系结构。因此，我们避免了需要处理小图像补丁并重新组装他们的完全连接图层[26].我们的默认架构是U-net[35]

图4. SID数据集（Sony x100子集）中室内图像上的补丁放大因子效应。放大系数作为外部输入提供给我们的管道，类似与相机中的ISO设置。更高的放大倍数可以产生更明亮的图像，这张图显示了我们的管道输出具有不同的放大因子。

放大率决定了输出的亮度。在我们的流水线中，放大率设置在外部，并作为输入提供给管道，类似于相机中的ISO设置。图4显示了不同放大比率的效果。用户可以通过设置不同的放大系数来调节输出图像的亮度。在测试时，管道执行盲噪声抑制和颜色转换。网络直接在sRGB空间输出处理后的图像。

## 4.2 训练

我们使用L1损失和Adam优化器从头开始训练网络[21].在训练期间，网络输入是短曝光图像的原始数据，而参考标准是sRGB空间中相应的长时间曝光图像（由原始图像处理库libraw处理）。我们为每台相机训练一个网络。放大率被设置为用于训练和测试的输入和参考图像之间的曝光差异（例如，x100，x250或x300）。在每次迭代中，我们随机裁剪一个512*512的补丁用于训练，并应用随机翻转和旋转进行数据增强。学习率最初设定为10e-4，在2000epoch之后降至10e-5。总共训练4000个epoch

# 5. 实验

## 5.1 定性结果和感知实验

**和传统管道比较**。我们最初的基准是传统的相机处理流水线，在量化放大。（我们使用与我们的管线相同的放大比率）。图5，6和7显示了与该基线的定性比较。在极端低光条件下由传统管线生成的图像受到严重的噪音和颜色失真的影响。

**和去噪以及突发处理的比较**。自然的下一步是将现有的去噪算法应用到传统流水线的输出中。近期对实际数据的仔细评估表明，BM3D[7]优于最近在实际图像上的去噪模型[32].因此，我们使用BM3D作为参考去噪算法。图7显示了结果。请注意，BM3D是一种非盲降噪方法，需要将噪声级别作为参赛进行外部指定。小的噪声级别设置可能会在图像上留下感知上明显的噪声，而较大的级别可能会过于平滑。如图7所示，这两种效应可以共存于相同的图像中，因为均匀的加性噪声不适用于真实的低光图像。相比之下，我们的流水线可以在局部适应数据的情况下执行盲噪声抑制。此外，事后去噪不能解决传统流水线输出中存在的其他伪像，例如色彩失真。

我们也比较了突发消噪[24,14]。由于我们数据集中的图像序列已经对齐，所以我们比较的突发消噪管道是理想化的：它从完美对齐中收益，这在实践中并不存在。由于对齐已经被处理，我们通过8个图像序列的每个像素中值进行突发降噪。

使用参考长曝光图像的PSNR/SSIM比较对于BM3D和突发处理是不公平的，因为这些基线必须使用经过不同处理的输入图像。为了公平比较，我们通过使用参考图像的白平衡系数来减少颜色偏差。另外，我们将给予基线逐个通道的图像放缩为参考图像相同的平均值。这些调整使得基线产生的图像颜色和亮度方面更接近参考图像。请注意，这相当于使用特权信息来帮助基线。

为了评估由我们的管道，BM3D去噪和突发去噪产生的图像的相对质量，我们基于部署在亚马逊Mechanical Turk平台上的盲随机A/B测试进行感知实验[4]。每次比较都会将由两条不同管线产生的相应图像呈现给MTurk工作人员，他们必须确定哪个图像具有更高的质量。图像以随机顺序呈现，具有随机左右顺序，并且不显示不同图像的来源。10名MTruk工作人员进行了1180次比较。表2显示了工人选择由所提供的管线产生的图像在其中一条基线产生的对应图像的速率。我们用来自测试集的两个子集的图像进行了实验：索尼x300（具有挑战性）和索尼x100（更容易）。我们的管道在性能上大大超越了具有挑战性的x300系列的基线，并且与易于使用的x100系列相媲美。回想一下，由于预处理提供给基线的数据，实验偏向于基线。还要注意，突发去噪使用来自8幅完美对齐图像的信息。

               | Sony x300 set | Sony x100 set
---------------|---------------|---------------               
 Ours > BM3D   |   92.4%       |    59.3%
 Ours > Burst  |   85.2%       |    47.3%

表2. 用于比较所提供的管道与BM3D和突发降噪的感知实验。正如文中所述，实验偏向于基线。所呈现的单幅图像流水线仍然明显优于具有挑战性的x300套件的基线，并且与易于使用的x100套件相媲美。

**智能收集图像的定性结果**。 我们期望在为特定相机传感器训练专用网络时获得最佳结果。然后，我们用交叉传感器泛化的初步试验表明，这可能并不总是必要的。我们已将针对索尼子集SID训练的模型应用于iPhone 6s智能手机拍摄的图像，该智能手机还具有Bayer滤波器阵列和14位原始数据。我们使用应用程序来手动设置ISO和其他参赛，并导出原始数据进行处理。一个代表性的结果如图6所示。传统管道处理的低光数据遭受严重的噪声和色移。我们的网络的结果是训练来自不同相机的图像，具有良好的对比度，低噪音和良好的色彩调节。

图6. 将使用iPhone 6s智能手机拍摄的SID训练网络应用于低光原始图像。（a）在夜间拍摄的具有ISO400，光圈f/2.2和曝光时间0.05s的iPhone 6s的原始图像。该图像由传统的图像处理流水线处理并放缩以匹配参考图像的亮度。（b）我们网络的输出，放大率x100

## 5.2 对照实验

表3（第一行）以峰值信噪比（PSNR）和结构相似性（SSIM）[38]报告了所提供的流水线的准确性。我们现在描述一系列控制实验，评估管道中不同元素的影响。


图7. Sony x3000套装的图像。（a）由传统图像处理流水线处理的低光输入和线性放缩。（b）相同，然后是BM3D去噪。（c）我们的结果。

Condition                 |      Sony       |    Fuji
--------------------------|-----------------|--------------
1. Our default pipeline   |   28.88/0.787   |  26.61/0.680
2. U-net → CAN            |   27.40/0.792   |  25.71/0.710
3. Raw → sRGB             |   17.40/0.554   |  25.11/0.648
4. L1 → SSIM loss         |   28.64/0.817   |  26.20/0.685
5. L1 → L2 loss           |   28.47/0.784   |  26.51/0.680
6. Packed → Masked        |   26.95/0.744   |       –
7. X-Trans 3 × 3 → 6 × 6  |        –        |  23.05/0.567
8. Stretched references   |   18.23/0.674   |  16.85/0.535

表3. 对照实验。 该表报告了每种情况下的平均PSNR/SSIM

**网络结构**。 我们从比较不同的网络架构开始。表3（第二行）报告了使用CAN[5]替换U-net[35]（我们的默认架构）的结果。U-net在两套装置上具有更高的PSNR。虽然由CAN生成的图像具有较高的SSIM，但它们有时会遭受颜色的损失。图8显示了Fuji x300套装的补丁。这些颜色不能通过CAN正确恢复。

图8. Fuji x300测试集的映像补丁上的网络体系结构比较。 （a）使用CAN结构，颜色不能正确恢复。 （b）使用U-net。放大细节。

**输入色彩空间**。 大多数现有的去噪方法对已经由传统图像处理流水线处理的sRGB图像进行操作。我们发现直接在原始传感器数据上操作在极端低光条件下更加有效。表3（第3行）显示了将流水线应用于传统流水线生成的sRGB图像时的结果

**损失函数**。 我们默认使用L1损失，但已经评估了许多其他损失函数。如表3所示（第4行和第5行），用L2或SSIM替代L1损失[43]产生可比较但结果。我们还没有观察到这些损失函数中但任何一个的系统感知益处。添加总变差损失不会提高准确性。添加GAN损失会显著降低准确性。

**数据安排**。 原始传感器数据在单个通道中具有所有颜色。为卷积网络安排原始数据的常见选择是将颜色值打包到具有相应较低空间分辨率的不同通道中，或者复制和遮盖不同的颜色[10].我们默认使用包装。如表3（第6行）所示，掩盖拜耳数据（索尼子集）比打包产生更低的PSNR/SSIM；掩蔽方法的典型感知伪像是输出中某些色调的损失。

X-Trans数据在结构上和拜耳数据非常不同，并且以6*6块排列。一种选择是将其打包成36个通道。相反，我们在相邻元素之间交换一些值以创建一个3*3模式，该模式被打包成9个通道。如表3（第7行）所示，6*6包装产生更低的PSNR/SSIM；典型的感知伪影是颜色和细节的丧失。

**后期处理**。在最初的实验中，我们参考图像的流水线中包含了直方图拉伸。因此，除了处理流水线的其余部分之外，网络必须学习直方图拉伸。尽管尝试了许多网络架构和损失功能，但我们没有成功培训网络来执行此任务。如表（第8行）所示，当直方图拉伸应用于参考图像时，网络的准确性显著下降（因此网络必须学习直方图拉伸）。我们的实验表明，我们的流水线不容易学习在整个图像上对全局直方图统计进行建模和操作，并且在面对此任务时容易过度拟合训练数据。因此，我们排除了管道中的直方图拉伸，并可以选择将其应用于后处理。图9显示了一个典型的结果，其中试图学习直方图拉伸在测试时间产生可见的伪像。对未拉伸的参考图像进行训练的结果更暗但更清晰。

# 6. 讨论

由于低光子数和低信噪比，快速低光成像是一项艰巨的挑战。在传统的信号处理技术中，视频速率在sub-lux条件下在黑暗中进行成像被认为是不切实际的。在本文中，我们提出了夜视（SID）数据集，该数据集是为支持开发可实现这种极端成像的数据驱动方法而创建的。使用SID，我们开发了一种简单的流水线，改进了传统的低光图像处理。所提出的流水线基于完全卷积网络的端到端训练。实验证明有希望的结果，成功的噪声抑制和正确的SID数据颜色转换。

所呈现的工作为未来的研究开辟了许多机会。我们的工作没有涉及HDR色调映射。（注意图1（c）中的饱和区域。）SID数据集受到限制，因为它不包含人类和动态对象。所提供的管道的结果是不完善的，并且在未来的工作中可以改进；x300子集特别具有挑战性。图10（d）展示了所提出方法的输出中一些假象。

所提供的流水线的另一个限制是放大比率必须从外部选择。从输入中推断出一个很好的放大率，这很有用，类似于Auto ISO。此外，我们目前假设专用网络是针对给定相机传感器进行训练的。我们对交叉传感器概括的初步实验是令人鼓舞的，未来的工作可能会进一步研究低光成像网络的泛化能力。

未来工作的另一个机会是运行时优化。所提供的流水线分别处理全分辨率索尼和富士图像需要0.38秒和0.66秒；尽管可以实时生成低分辨率预览，但对于以全分辨率进行实时处理的速度还不够快。

我们期望未来的工作能够进一步提高图像质量，例如通过系统优化网络架构和训练程序。我们希望SID数据集和我们的实验结果能够刺激和支持这种系统的调查。
